{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Engine (MovieLens 100k data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyspark.ml Implementation using  Alternating Least Squares (ALS) Matrix Factorization\n",
    "ALS works by trying to find the optimal representation of a user and a product matrix â€“ which when combined, should accurately represent the original dataset. The genius part of ALS is that it alternates between finding the optimal values for the user matrix and the product matrix. \n",
    "\n",
    "**Assumptions and FYI:**\n",
    "- Treating the entries in user-item matrix as explicit feedback\n",
    "- Using DataFrame based API, pyspark.sql.DataFrame to usemachine learning pipelines, pyspark.ml\n",
    "- Scaling of the regularisation parameter is done in solving each ALS (makes regParam less dependent of scale of data)\n",
    "- Cold start strategy to drop any rows in the DataFrame of predictions that contain NaN values\n",
    "- Model evaluation will be based on root-mean-square error (RMSE) of rating prediction\n",
    "- 'NOT' creating test-train split (as mentioned in the question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](https://i.pinimg.com/originals/ba/f0/c8/baf0c80a9fea91e79365630709a1fa5c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession #to connect to spark cluster/core\n",
    "from pyspark import SparkContext  #to read file aptly\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up \"SparkSession\"  (and \"SparkContext\" to read files aptly)\n",
    "**Note**: It provides a single point of entry to interact with underlying Spark functionality;\n",
    "allows programming Spark with DataFrame and Dataset APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"RecommendationSystems\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "        \n",
    "sc=SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing file as RDD and cleaning it; Mapping data to 'Rating' obj; Making ADS_SDF\n",
    "**Note**: SDF is Spark Dataframe (cretaing it for further convenient processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing file from current library to RDD object\n",
    "movielens_RDD = sc.textFile(\"ml-100k/u.data\")\n",
    "\n",
    "#Cleaning up (Movielens RDD is tab separated) \n",
    "#Note: RDD schema ~ \"user\" \"product\" \"rating\" \"timestamp\"\n",
    "movielens_RDD_clean=movielens_RDD.map(lambda x:x.split('\\t'))\n",
    "\n",
    "#Mapping cleaned RDD to \"Rating\" object\n",
    "#Note: ADS RDD schema ~ \"user\" \"product\" \"rating\"(float)\n",
    "ADS_RDD=movielens_RDD_clean.map(lambda x: Row(int(x[0]),\\\n",
    "        int(x[1]), float(x[2])))\n",
    "ADS_SDF=spark.createDataFrame(ADS_RDD, ['userId', 'movieId', 'rating'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model (using pyspark.ml's ALS model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setting up the parameters for ALS\n",
    "rank_=7   #No.of Latent Factors (to be made)\n",
    "maxIter_=10   #No.of Times to repeat \n",
    "regParam_= 0.1   #Regularization Parameter in ALS\n",
    "\n",
    "#Instatiating ALS and Fitting model to whole data\n",
    "ALS_obj = ALS(rank=rank_, maxIter=maxIter_, regParam=regParam_, \n",
    "          userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", \n",
    "          coldStartStrategy=\"drop\")\n",
    "ALS_model = ALS_obj.fit(ADS_SDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluations (based on RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8000418417915021\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the model by computing the RMSE on the whole data\n",
    "predictions = ALS_model.transform(ADS_SDF)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 movie recommendations for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate top 10 movie recommendations for each user\n",
    "userRecs_SDF = ALS_model.recommendForAllUsers(10)\n",
    "\n",
    "#Manipulating SDF to get info in required form\n",
    "user_movieRecs_SDF=userRecs_SDF.select(\"userId\",\"recommendations.movieId\")\n",
    "user_movieRecs_DF=user_movieRecs_SDF.toPandas().sort_values(\"userId\")\n",
    "user_movieRecs_DF['movieId(s)']=[str(i)[1:-1] for i in user_movieRecs_DF.movieId]\n",
    "user_movieRecs_DF.drop('movieId',axis=1,inplace=True)\n",
    "\n",
    "#Exporting file to tab separated text file\n",
    "user_movieRecs_txt=user_movieRecs_DF.to_csv(sep='\\t', index=False)\n",
    "file_obj=open(\"Swapnil_Parkhe.txt\",'w')\n",
    "file_obj.write(user_movieRecs_txt)\n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
