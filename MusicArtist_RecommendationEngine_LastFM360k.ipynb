{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicArtist-RecommendationEngine-LastFM360k.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SwapnilSParkhe/Big_Data_Analytics/blob/master/MusicArtist_RecommendationEngine_LastFM360k.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WinYt92lZbxQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recommendation Engine (Last.fm 360k data)"
      ]
    },
    {
      "metadata": {
        "id": "IOmGGgirZbxR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![\"Image\"](https://gigaom2.files.wordpress.com/2012/06/lastfmlogo.png)"
      ]
    },
    {
      "metadata": {
        "id": "A1tj5jQ0ZbxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation structure\n",
        "- Model based Collaborative Filtering using Alternating Least Squares (ALS) Matrix Factorization\n",
        "- Treating the entries in user-item association matrix as implicit feedback ('listenCount')\n",
        "- Using DataFrame based API, pyspark.sql.DataFrame to use machine learning pipelines, pyspark.ml\n",
        "- Model evaluation will be based on root-mean-square error (RMSE) of rating prediction\n",
        "- Tuning the hyperparameters involved"
      ]
    },
    {
      "metadata": {
        "id": "3od5vSrzZbxT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![\"Image\"](https://i.pinimg.com/originals/ba/f0/c8/baf0c80a9fea91e79365630709a1fa5c.png)"
      ]
    },
    {
      "metadata": {
        "id": "VCFQJ3-4aQnC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 0. Setting Up Google Colab related dependencies**"
      ]
    },
    {
      "metadata": {
        "id": "HctFUtZaaPtd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "eaa0d83c-ed5e-4582-ab71-d3a861d89989"
      },
      "cell_type": "code",
      "source": [
        "#Installing libraries\n",
        "#This installs Apache Spark 2.3.0, Java 8, and Findspark, a library that makes it easy for Python to find Spark.\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.3.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "#Getting the data from the web\n",
        "!wget http://mtg.upf.edu/static/datasets/last.fm/lastfm-dataset-360K.tar.gz -P drive/MSBA/Big_Data_Analytics\n",
        "  \n",
        "#Untarring the data\n",
        "import tarfile\n",
        "tar_ref = tarfile.open('drive/MSBA/Big_Data_Analytics/lastfm-dataset-360K.tar.gz', \"r:gz\")\n",
        "tar_ref.extractall()\n",
        "tar_ref.close()\n",
        "\n",
        "#Setting up environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.0-bin-hadoop2.7\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-30 18:32:46--  http://mtg.upf.edu/static/datasets/last.fm/lastfm-dataset-360K.tar.gz\n",
            "Resolving mtg.upf.edu (mtg.upf.edu)... 84.89.139.55\n",
            "Connecting to mtg.upf.edu (mtg.upf.edu)|84.89.139.55|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 569202935 (543M) [application/x-gzip]\n",
            "Saving to: ‘drive/MSBA/Big_Data_Analytics/lastfm-dataset-360K.tar.gz.1’\n",
            "\n",
            "-360K.tar.gz.1       15%[==>                 ]  81.89M  1.72MB/s    eta 4m 32s "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "lastfm-dataset-360K 100%[===================>] 542.83M  1.72MB/s    in 5m 16s  \n",
            "\n",
            "2018-04-30 18:38:03 (1.72 MB/s) - ‘drive/MSBA/Big_Data_Analytics/lastfm-dataset-360K.tar.gz.1’ saved [569202935/569202935]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXNr71sDZbxU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Importing relevant libraries"
      ]
    },
    {
      "metadata": {
        "id": "0wvE6VgzZbxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Library to help Python find spark easily\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "#Importing libraries\n",
        "from pyspark.sql import SparkSession #to connect to spark cluster/core\n",
        "from pyspark import SparkContext  #to read file aptly\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQ9Y98tfZbxZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Setting up \"SparkSession\"  (and \"SparkContext\" to read files aptly)\n",
        "**Note**: It provides a single point of entry to interact with underlying Spark functionality;\n",
        "allows programming Spark with DataFrame and Dataset APIs"
      ]
    },
    {
      "metadata": {
        "id": "ZW00OnjUZbxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .appName(\"RecommendationSystems\") \\\n",
        "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "        .getOrCreate()\n",
        "        \n",
        "sc=SparkContext.getOrCreate()\n",
        "\n",
        "#sqlContext=SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ycJLY9SgZbxe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Importing file as RDD; Cleaning, Manipulating and Handling data; Making ADS_SDF\n",
        "**Note**: SDF is Spark Dataframe (cretaing it for further convenient processing)"
      ]
    },
    {
      "metadata": {
        "id": "EWh3e7iuZbxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Importing file from current library to RDD object\n",
        "lastfm_RDD = sc.textFile(\"lastfm-dataset-360K/usersha1-artmbid-artname-plays.tsv\")\n",
        "\n",
        "#Cleaning up (lastfm file's line elements are tab separated) \n",
        "#Note: RDD schema ~ \"user_id\" \"artsit_id\" \"artist-name\" plays\"\n",
        "lastfm_RDD_clean=lastfm_RDD.map(lambda line:line.split('\\t'))\n",
        "lastfm_RDD_clean_1=lastfm_RDD_clean.map(lambda x: (x[0],x[1],x[3]))\n",
        "\n",
        "#Convert strings-items into integers (required for ALS in Py using DF)\n",
        "users = lastfm_RDD_clean_1.map(lambda x: x[0]).distinct().zipWithIndex()\n",
        "artists = lastfm_RDD_clean_1.map(lambda x: x[1]).distinct().zipWithIndex()\n",
        "\n",
        "#Substituting the ObjectIDs in the ratings RDD with the corresponding int values\n",
        "lastfm_RDD_clean_1 = lastfm_RDD_clean_1.map(lambda r: (r[0], (r[1], r[2]))).join(users).map(lambda r: (r[1][1], r[1][0][0], r[1][0][1]))\n",
        "lastfm_RDD_clean_1 = lastfm_RDD_clean_1.map(lambda r: (r[1], (r[0], r[2]))).join(artists).map(lambda r: (r[1][0][0], r[1][1], r[1][0][1]))\n",
        "\n",
        "#Collecting all plays at user-artist level\n",
        "plays = lastfm_RDD_clean_1.map(lambda x: x[2]).collect()\n",
        "\n",
        "#Extracting relevant columns to \"Rating\" object\n",
        "#Note: ADS RDD schema ~ \"user_id\" \"artist_id\" \"plays\"\n",
        "ADS_RDD=lastfm_RDD_clean_1.map(lambda x: Row(int(x[0]), int(x[1]), float(x[2])))\n",
        "ADS_SDF=spark.createDataFrame(ADS_RDD, ['userId', 'artistId', 'plays'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMLPptw8Zbxi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Training Model (using pyspark.ml's ALS model) - \"BasicVersion\""
      ]
    },
    {
      "metadata": {
        "id": "WuwSXxJXZbxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Setting up the parameters for ALS\n",
        "rank_=7   #No.of Latent Factors (to be made)\n",
        "maxIter_=10   #No.of Times to repeat \n",
        "regParam_= 0.1   #Regularization Parameter in ALS\n",
        "\n",
        "#Instatiating ALS and Fitting model to whole data\n",
        "ALS_obj = ALS(rank=rank_, maxIter=maxIter_, regParam=regParam_, \n",
        "              coldStartStrategy=\"drop\", implicitPrefs=True,\n",
        "              userCol=\"userId\", itemCol=\"artistId\", ratingCol=\"plays\")\n",
        "ALS_model = ALS_obj.fit(ADS_SDF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZmBa_fgZbxn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Model Evaluations (based on RMSE) - \"BasicVersion\""
      ]
    },
    {
      "metadata": {
        "id": "ubJDnL_AZbxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eeb9a227-6bd2-4591-da7d-3ef5e3ad2ddf"
      },
      "cell_type": "code",
      "source": [
        "#Evaluating the model by computing the RMSE on the whole data\n",
        "def compute_RMSE(model,data):\n",
        "    \n",
        "    \"\"\" Takes ALS models and testing data in SDF form \n",
        "    as input and returns RMSE value \"\"\"\n",
        "    \n",
        "    predictions = model.transform(data)\n",
        "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"plays\",\n",
        "                                    predictionCol=\"prediction\")\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "    \n",
        "    return rmse\n",
        " \n",
        "compute_RMSE(ALS_model,ADS_SDF)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650.7785559354666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "4vPrYsxKZbxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Top 10 movie recommendations for all users - \"BasicVersion\""
      ]
    },
    {
      "metadata": {
        "id": "7e2ayW9uZbxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate top 10 movie recommendations for each user\n",
        "userRecs_SDF = ALS_model.recommendForAllUsers(10)\n",
        "\n",
        "#Manipulating SDF to get info in required form\n",
        "user_artistRecs_SDF=userRecs_SDF.select(\"userId\",\"recommendations.artistId\")\n",
        "user_artistRecs_DF=user_artistRecs_SDF.toPandas().sort_values(\"userId\")\n",
        "user_artistRecs_DF['artistId(s)']=[str(i)[1:-1] for i in user_artistRecs_DF.artistId]\n",
        "user_artistRecs_DF.drop('artistId',axis=1,inplace=True)\n",
        "\n",
        "#Exporting file to tab separated text file\n",
        "user_artistRecs_txt=user_artistRecs_DF.to_csv(sep='\\t', index=False)\n",
        "file_obj=open(\"Music_Reco_360k.txt\",'w')\n",
        "file_obj.write(user_artistRecs_txt)\n",
        "file_obj.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcxJCVcd5zuU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7.Tuning and Evaluating tuned Models - \"TunedVersion\""
      ]
    },
    {
      "metadata": {
        "id": "PVI9Ah-75zBX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model Params\n",
        "seed_ = 561\n",
        "maxIter_ = 10\n",
        "regParam_ = 0.1\n",
        "alpha_ = 0.01\n",
        "ranks = [10,25,50]\n",
        "\n",
        "#Eval params\n",
        "errors = [0, 0, 0] #list for storing errors of hyperParams\n",
        "err_ID = 0 #iterating errorID\n",
        "tolerance = 0.02\n",
        "\n",
        "#Print params\n",
        "min_error = float('inf')\n",
        "best_rank = -1\n",
        "best_iteration = -1\n",
        "\n",
        "#Hyperparamenter tuning (5-times RandomSplit Hold-Out Cross-Validation)\n",
        "for rank_ in ranks:\n",
        "    rmse = 0\n",
        "    for i in range(5):\n",
        "        print(\"Running rank : iter ::\", rank_,':',i+1)\n",
        "        #Randomly Splitting the SDF data (train:valid:test :: 60%:30%:10%)\n",
        "        train_SDF, valid_SDF, test_SDF = ADS_SDF.randomSplit([0.6, 0.3, 0.1])\n",
        "        valid_predict_SDF = valid_SDF.select(['userId', 'artistId'])\n",
        "        test_predict_SDF = test_SDF.select(['userId', 'artistId'])\n",
        "        \n",
        "        #Instatiating ALS and Fitting model to train data\n",
        "        ALS_obj = ALS(rank=rank_, maxIter=maxIter_, regParam=regParam_, alpha=alpha_,\n",
        "                      coldStartStrategy=\"drop\", implicitPrefs=True, seed=seed_,\n",
        "                      userCol=\"userId\", itemCol=\"artistId\", ratingCol=\"plays\")\n",
        "        ALS_model = ALS_obj.fit(train_SDF)\n",
        "    \n",
        "        #Collecting rmse for this specific split (and then adding for same hyperParams)\n",
        "        rmse += compute_RMSE(ALS_model,valid_SDF)\n",
        "        \n",
        "    \n",
        "    #Summarizing error(by avg all split rounds' rmse) for given hyperParams\n",
        "    error = rmse/5\n",
        "    errors[err_ID] = error\n",
        "    err_ID += 1 #iterating err_ID with rank iterations\n",
        "    print ('For hyperParam \"rank\" %s the RMSE is %s' % (rank_, error))\n",
        "    \n",
        "    #Printing best model\n",
        "    if error < min_error:\n",
        "        min_error = error\n",
        "        best_rank = rank_\n",
        "\n",
        "print ('The best model was trained with hyperParam \"rank\": %s' % best_rank)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Os1KgWO6aIOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Final Model - \"TunedVersion\""
      ]
    },
    {
      "metadata": {
        "id": "wJKH2sXWZbx0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFV5JF5MfXtD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}